Agent configuration:
------------------------------
OPTION: 'agent-actions' = '3'
OPTION: 'agent-horizon' = '5'
OPTION: 'ct-depth' = '32'
OPTION: 'environment' = 'tiger'
OPTION: 'exploration' = '0.99'
OPTION: 'explore-decay' = '0.999'
OPTION: 'intermediate-ct' = '0'
OPTION: 'load-ct' = ''
OPTION: 'log' = 'log/tiger_rps1'
OPTION: 'mc-timelimit' = '500'
OPTION: 'observation-bits' = '2'
OPTION: 'reward-bits' = '7'
OPTION: 'terminate-age' = '20000'
OPTION: 'write-ct' = 'ct-files/tiger_rps1'

starting agent/environment interaction loop...
cycle: 1
average reward: 0
explore rate: 0.99
cycle: 2
average reward: 49.5
explore rate: 0.98901
cycle: 4
average reward: 52.25
explore rate: 0.987033
cycle: 8
average reward: 77
explore rate: 0.983091
cycle: 16
average reward: 78.375
explore rate: 0.975254
cycle: 32
average reward: 74.9375
explore rate: 0.959766
cycle: 64
average reward: 77.6875
explore rate: 0.929525
cycle: 128
average reward: 71.4141
explore rate: 0.871871
cycle: 256
average reward: 72.0156
explore rate: 0.767069
cycle: 512
average reward: 74.9375
explore rate: 0.593745
cycle: 1024
average reward: 80.9424
explore rate: 0.355738
cycle: 2048
average reward: 86.4907
explore rate: 0.1277
cycle: 4096
average reward: 92.27
explore rate: 0.0164554
cycle: 8192
average reward: 96.0459
explore rate: 0.000273243
cycle: 16384
average reward: 98.0426
explore rate: 7.53406e-08


SUMMARY
agent age: 20000
average reward: 98.4005
